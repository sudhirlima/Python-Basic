{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### **Assignment Code: DA-AG-011**\n",
        "\n",
        "\n",
        "# Logistic Regression | **Assignment**\n",
        "---\n",
        "\n",
        "### Instructions: Carefully read each question. Use Google Docs, Microsoft Word, or a similar tool to create a document where you type out each question along with its answer. Save the document as a PDF, and then upload it to the LMS. Please do not zip or archive the files before uploading them. Each question carries 20 marks.\n",
        "\n",
        "### Total Marks: 200"
      ],
      "metadata": {
        "id": "d_LsjpKy06ha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 1:**  What is Logistic Regression, and how does it differ from Linear Regression?\n",
        "#### Answer:\n",
        "**Logistic Regression** is a statistical model used for binary or multiclass classification, which estimates the probability that a given input belongs to a particular category. It uses the **Sigmoid function** to map predicted values to probabilities between 0 and 1.\n",
        "\n",
        "**How does it differ from Linear Regression ?**\n",
        "\n",
        "| Feature| Linear Regression|Logistic Regression|\n",
        "|:-------:|:--------------:|:------------------:|\n",
        "| Definition           | Predicts a **continuous numeric value** <BR> based on input features | Predicts the **probability of a class** <br> based on input features   |\n",
        "| Purpose              | Regression problems                                              | Classification problems                                           |\n",
        "| Output Range         | Any real number                                                  | Between 0 and 1                                                   |\n",
        "| Function Used        | Linear equation                                                  | Sigmoid (logistic) function                                       |\n",
        "| Use Case             | Predicting prices, scores, etc.                                  | Predicting categories (e.g., spam vs. not spam, pass vs fail, <br> diabetic vs non-diabetic)                   |"
      ],
      "metadata": {
        "id": "mfjVboRD1mwW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 2:**  Explain the role of the Sigmoid function in Logistic Regression.\n",
        "#### Answer: Role of Sigmoid Function in Logistic Regresion:\n",
        "The **Sigmoid function** maps any real-valued number, to a value between (0,1), making it ideal for expressing **probabilites**.\n",
        "\n",
        "#### Formula: \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "- \\sigma(z) is the sigmoid function applied to input z\n",
        "- e^{-z} is the exponential decay term\n",
        "- The output is always between 0 and 1\n",
        "\n",
        "#### **Role in Logistic Regression:**\n",
        "- Converts the linear combination of inputs (z) into a probability.\n",
        "- Helps classify inputs by applying a threshold (e.g., ≥ 0.5 → class 1, < 0.5 → class 0).\n",
        "- Ensures output is interpretable as a likelihood of belonging to a class.\n"
      ],
      "metadata": {
        "id": "jK9pvyfB1oeF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 3:**  What is Regularization in Logistic Regression and why is it needed?\n",
        "#### Answer: Regularization is a technique used to prevent overfitting by adding a penalty term to the loss function, discouraging overly complex models.\n",
        "\n",
        "Why It's Needed:\n",
        "- Helps control model complexity by shrinking large weights.\n",
        "- Improves generalization to unseen data.\n",
        "- Reduces variance without significantly increasing bias.\n",
        "\n",
        "Types Commonly Used:\n",
        "- L1 Regularization (Lasso): Adds \\lambda \\sum |w_i| to the loss function. Encourages sparsity.\n",
        "- L2 Regularization (Ridge): Adds \\lambda \\sum w_i^2 to the loss. Penalizes large weights smoothly.\n",
        "\n"
      ],
      "metadata": {
        "id": "rsB0olsP1pg0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 4:**  What are some common evaluation metrics for classification models, and why are they important?\n",
        "#### Answer: Some common Evaluation Metrics for Classification Models:\n",
        "| Metric|Description|Why It’s Important|\n",
        "|:-----:|:--------:|:------------------:|\n",
        "| **Accuracy** | Proportion of correct predictions| Good for balanced datasets|\n",
        "| **Precision**| \\( \\frac{\\text{TP}}{\\text{TP} + \\text{FP}} \\) — True Positives over predicted positives | Measures exactness (low false positives)     |\n",
        "| **Recall**   | \\( \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} \\) — True Positives over actual positives | Measures completeness (low false negatives)  |\n",
        "| **F1 Score** | Harmonic mean of precision and recall | Balances precision and recall|\n",
        "| **ROC-AUC**  | Area under the Receiver Operating Characteristic curve                       | Evaluates model’s ability to distinguish classes |\n",
        "\n",
        "#### Why They Matter:\n",
        "  - Different metrics highlight different aspects of performance.\n",
        "  - Crucial for imbalanced datasets (e.g., fraud detection).\n",
        "  - Help choose the best model for the specific business or domain need.\n",
        "\n",
        "#### Extended Evaluation Tools\n",
        "  - Accuracy Score: Direct metric computed via accuracy_score(y_true, y_pred).\n",
        "  - Confusion Matrix: Tabular summary of TP, TN, FP, FN — foundation for other metrics.\n",
        "  - Classification Report: Consolidated view of precision, recall, F1-score, and support per class.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YpAqPCQL1qGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 5:**   Write a Python program that loads a CSV file into a Pandas DataFrame, splits into train/test sets, trains a Logistic Regression model, and prints its accuracy. (Use Dataset from sklearn package)\n",
        "(Include your Python code and output in the code box below.)\n",
        "#### Answer: We will be using breast_cancer_data from sklearn.datasets."
      ],
      "metadata": {
        "id": "SgVakQEJ1qnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load dataset from sklearn - breast_cancer data.\n",
        "data = load_breast_cancer()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "# Since the data is pretty clean with no null or missing values. and all columns are float. we will proceed with Train_test_split.\n",
        "\n",
        "# Splitting into train test sets.\n",
        "X = df.drop('target', axis=1)\n",
        "y = df.target\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Reg. model.\n",
        "model = LogisticRegression(max_iter =1000 )   #  max_iter=1000 ensures convergence.\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print (\"Accuracy:\", round(accuracy * 100, 2), \"%\")\n",
        "\n",
        "# Evaluation metrics.\n",
        "\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "#Insights.: The model has an accuracy of 95.61 %\n",
        "# - The model performs very well, especially in identifying malignant tumors (high recall).\n",
        "# - False negatives are low, which is crucial in healthcare.\n",
        "# Precision: Of all predicted malignant cases, how many were truly malignant?\n",
        "# - High precision (e.g., 0.95) → few false positives.\n",
        "# Recall: Of all actual malignant cases, how many were correctly identified?\n",
        "# - High recall (e.g., 0.99) → few false negatives.\n",
        "# F1-score: Harmonic mean of precision and recall.\n",
        "# - Balances both metrics, especially useful when classes are imbalanced.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5vrBGMUT-RkV",
        "outputId": "57239955-8891-467d-d411-34982d703d9b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.61 %\n",
            "\n",
            "Confusion Matrix:\n",
            " [[39  4]\n",
            " [ 1 70]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.91      0.94        43\n",
            "           1       0.95      0.99      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 6:**  Write a Python program to train a Logistic Regression model using L2 regularization (Ridge) and print the model coefficients and accuracy.(Use Dataset from sklearn package)\n",
        "(Include your Python code and output in the code box below.)\n",
        "#### Answer: We will be using breast cancer data for Logistic Regression with L2 (Ridge) Regularization.\n"
      ],
      "metadata": {
        "id": "jLEkn0sY1rDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression with L2 regularization (default)\n",
        "model = LogisticRegression(penalty='l2', solver='liblinear')  # 'liblinear' supports L2\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"Model Accuracy:\", round(accuracy * 100, 2), \"%\")\n",
        "print(\"\\nModel Coefficients:\")\n",
        "for feature, coef in zip(X.columns, model.coef_[0]):\n",
        "    print(f\"{feature}: {coef:.4f}\")\n",
        "\n",
        "#Note:\n",
        "# - penalty='l2' is the default, but explicitly specifying it makes the intent clear.\n",
        "# - solver='liblinear' is compatible with small datasets and L2 regularization.\n",
        "# - Coefficients show the weight each feature contributes to the decision boundary\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "uWCrzWUGCr41",
        "outputId": "4f00d942-5a48-4ff6-9351-a6000a62830e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 95.61 %\n",
            "\n",
            "Model Coefficients:\n",
            "mean radius: 2.1325\n",
            "mean texture: 0.1528\n",
            "mean perimeter: -0.1451\n",
            "mean area: -0.0008\n",
            "mean smoothness: -0.1426\n",
            "mean compactness: -0.4156\n",
            "mean concavity: -0.6519\n",
            "mean concave points: -0.3445\n",
            "mean symmetry: -0.2076\n",
            "mean fractal dimension: -0.0298\n",
            "radius error: -0.0500\n",
            "texture error: 1.4430\n",
            "perimeter error: -0.3039\n",
            "area error: -0.0726\n",
            "smoothness error: -0.0162\n",
            "compactness error: -0.0019\n",
            "concavity error: -0.0449\n",
            "concave points error: -0.0377\n",
            "symmetry error: -0.0418\n",
            "fractal dimension error: 0.0056\n",
            "worst radius: 1.2321\n",
            "worst texture: -0.4046\n",
            "worst perimeter: -0.0362\n",
            "worst area: -0.0271\n",
            "worst smoothness: -0.2626\n",
            "worst compactness: -1.2090\n",
            "worst concavity: -1.6180\n",
            "worst concave points: -0.6153\n",
            "worst symmetry: -0.7428\n",
            "worst fractal dimension: -0.1170\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 7:**  Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr' and print the classification report. (Use Dataset from sklearn package)\n",
        "(Include your Python code and output in the code box below.)\n",
        "#### Answer: Multiclass Logistic Regression with multi_class='ovr' using iris dataset.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T9taYbx712nl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load multiclass dataset\n",
        "data = load_iris()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression with One-vs-Rest strategy\n",
        "model = LogisticRegression(multi_class='ovr', solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy: \", round(accuracy * 100, 2), \"%\")\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred, target_names=data.target_names))\n",
        "\n",
        "# Key Insights:\n",
        "# - multi_class='ovr' trains one binary classifier per class.\n",
        "# - solver='liblinear' supports OvR and small datasets.\n",
        "# - The classification report includes precision, recall, and F1-score for each class (setosa, versicolor, virginica).\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4Ea8Ani2DqVM",
        "outputId": "0cea3c23-f161-47ae-922c-3f2099d89069"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  95.61 %\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      1.00      1.00         9\n",
            "   virginica       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 8:**   Write a Python program to apply GridSearchCV to tune C and penalty hyperparameters for Logistic Regression and print the best parameters and validation accuracy. (Use Dataset from sklearn package)\n",
        "(Include your Python code and output in the code box below.)\n",
        "#### Answer: Hyperparameter Tuning with GridSearchCV"
      ],
      "metadata": {
        "id": "mdeaknFC12fu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "# Initialize model\n",
        "model = LogisticRegression(solver='liblinear')  # liblinear supports both l1 and l2\n",
        "\n",
        "# Grid search\n",
        "grid = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and validation score\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Best Cross-Validation Accuracy:\", round(grid.best_score_ * 100, 2), \"%\")\n",
        "\n",
        "# Evaluate on test set\n",
        "best_model = grid.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test Set Accuracy:\", round(test_accuracy * 100, 2), \"%\")\n",
        "\n",
        "#  Insights:\n",
        "# - C controls regularization strength: lower values = stronger regularization.\n",
        "# - penalty: 'l1' for sparse models, 'l2' for ridge-style regularization.\n",
        "# - solver='liblinear' is required for 'l1' penalty.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "S4fBuIPvEoB_",
        "outputId": "79ecb934-53f6-4032-e37b-38c697f18be6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 100, 'penalty': 'l1'}\n",
            "Best Cross-Validation Accuracy: 96.7 %\n",
            "Test Set Accuracy: 98.25 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 9:**  Write a Python program to standardize the features before training Logistic Regression and compare the model's accuracy with and without scaling. (Use Dataset from sklearn package)\n",
        "(Include your Python code and output in the code box below.)\n",
        "#### Answer: Here is the code that:\n",
        "- Loads a dataset from sklearn\n",
        "- Trains Logistic Regression with and without feature scaling\n",
        "- Compares the accuracy of both models"
      ],
      "metadata": {
        "id": "vEnyPx7912WL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- Model without scaling ---\n",
        "model_raw = LogisticRegression(max_iter=1000)\n",
        "model_raw.fit(X_train, y_train)\n",
        "y_pred_raw = model_raw.predict(X_test)\n",
        "accuracy_raw = accuracy_score(y_test, y_pred_raw)\n",
        "\n",
        "# --- Model with scaling ---\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_scaled = LogisticRegression(max_iter=1000)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "# --- Results ---\n",
        "print(\"Accuracy without Scaling:\", round(accuracy_raw * 100, 2), \"%\")\n",
        "print(\"Accuracy with Scaling   :\", round(accuracy_scaled * 100, 2), \"%\")\n",
        "\n",
        "\n",
        "# Insights:\n",
        "# - Standardization rescales features to have mean 0 and variance 1.\n",
        "# - Logistic Regression (especially with regularization) benefits from scaling because it's sensitive to feature magnitude.\n",
        "# - There's a noticeable improvement in accuracy with scaling, especially when features vary widely in scale.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OtLe1LJnH3n5",
        "outputId": "7ba49be0-ea1c-4ae6-e941-a64f0b081bca"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without Scaling: 95.61 %\n",
            "Accuracy with Scaling   : 97.37 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 10:**   Imagine you are working at an e-commerce company that wants to predict which customers will respond to a marketing campaign. Given an imbalanced dataset (only 5% of customers respond), describe the approach you'd take to build a Logistic Regression model — including data handling, feature scaling, balancing classes, hyperparameter tuning, and evaluating the model for this real-world business use case.\n",
        "#### Answer: This is an imbalanced classification problem using Logistic Regression in an e-commerce setting:\n",
        "\n",
        "#### Business Scenario\n",
        " - Goal: Predict which customers will respond to a marketing campaign\n",
        " - Challenge: Only 5% of customers respond → highly imbalanced dataset\n",
        "\n",
        "Step-by-Step Approach\n",
        "\n",
        "1. Data Handling\n",
        "  - Explore & clean: Handle missing values, outliers, and categorical encoding (e.g., one-hot or label encoding).\n",
        "  - Feature engineering: Create meaningful features like:\n",
        "  - Recency, frequency, monetary value (RFM)\n",
        "  - Past campaign interactions\n",
        "  - Customer segmentation tags\n",
        "\n",
        "2. Feature Scaling\n",
        "  - Apply StandardScaler to normalize numerical features.\n",
        "  - Logistic Regression is sensitive to feature magnitude, especially with regularization.\n",
        "\n",
        "3. Class Balancing Since only 5% respond:\n",
        "  - Resampling techniques:\n",
        "  - SMOTE (Synthetic Minority Over-sampling Technique) to generate synthetic positives.\n",
        "  - Random undersampling of majority class (optional).\n",
        "  - Class weights:\n",
        "  - Use class_weight='balanced' in LogisticRegression to penalize misclassification of minority class.\n",
        "\n",
        "4. Model Training:\n",
        "\n",
        "  ``` model = LogisticRegression(class_weight='balanced', solver='liblinear')```\n",
        "\n",
        "  - Use solver='liblinear' for small datasets and L1/L2 regularization support.\n",
        "\n",
        "5. Hyperparameter Tuning\n",
        "  - Use GridSearchCV to tune:\n",
        "    - C: Regularization strength\n",
        "    - penalty: 'l1' or 'l2'\n",
        "    - class_weight: 'balanced' vs custom weights\n",
        "\n",
        "6. Evaluation Metrics:\n",
        "  - Accuracy is misleading here. Focus on:\n",
        "\n",
        "| Metric       | Why It Matters                                      |\n",
        "|--------------|-----------------------------------------------------|\n",
        "| Precision    | Avoid false positives (wasting marketing budget)    |\n",
        "| Recall       | Capture as many responders as possible              |\n",
        "| F1 Score     | Balance between precision and recall                |\n",
        "| ROC-AUC      | Overall ability to distinguish responders           |\n",
        "\n",
        "  - Use confusion matrix to monitor false negatives (missed responders).\n",
        "  - Consider Precision-Recall curve for better insight in imbalanced settings.\n"
      ],
      "metadata": {
        "id": "UM_ldVxz12Ge"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBjYlFJksQml",
        "outputId": "ac84d4b6-e5f1-44ae-cf8d-e4443c8727cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": []
    }
  ]
}